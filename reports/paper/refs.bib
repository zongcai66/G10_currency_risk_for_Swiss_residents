@article{Mart_nez_Beltr_n_2023,
   title={Decentralized Federated Learning: Fundamentals, State of the Art, Frameworks, Trends, and Challenges},
   volume={25},
   ISSN={2373-745X},
   url={http://dx.doi.org/10.1109/COMST.2023.3315746},
   DOI={10.1109/comst.2023.3315746},
   number={4},
   journal={IEEE Communications Surveys; Tutorials},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Martínez Beltrán, Enrique Tomás and Pérez, Mario Quiles and Sánchez, Pedro Miguel Sánchez and Bernal, Sergio López and Bovet, Gérôme and Pérez, Manuel Gil and Pérez, Gregorio Martínez and Celdrán, Alberto Huertas},
   year={2023},
   pages={2983–3013} }

@ARTICLE{9566732,
  author={Alazab, Mamoun and RM, Swarna Priya and M, Parimala and Maddikunta, Praveen Kumar Reddy and Gadekallu, Thippa Reddy and Pham, Quoc-Viet},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Federated Learning for Cybersecurity: Concepts, Challenges, and Future Directions}, 
  year={2022},
  volume={18},
  number={5},
  pages={3501-3509},
  doi={10.1109/TII.2021.3119038}}

@misc{gabrielli2023survey,
      title={A Survey on Decentralized Federated Learning}, 
      author={Edoardo Gabrielli and Giovanni Pica and Gabriele Tolomei},
      year={2023},
      eprint={2308.04604},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{onoszko2021decentralized,
      title={Decentralized federated learning of deep neural networks on non-iid data}, 
      author={Noa Onoszko and Gustav Karlsson and Olof Mogren and Edvin Listo Zec},
      year={2021},
      eprint={2107.08517},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{augenstein2021jointly,
      title={Jointly Learning from Decentralized (Federated) and Centralized Data to Mitigate Distribution Shift}, 
      author={Sean Augenstein and Andrew Hard and Kurt Partridge and Rajiv Mathews},
      year={2021},
      eprint={2111.12150},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{LI2023103319,
    title = {Enhancing federated learning robustness in adversarial environment through clustering Non-IID features},
    journal = {Computers \& Security},
    volume = {132},
    pages = {103319},
    year = {2023},
    issn = {0167-4048},
    doi = {https://doi.org/10.1016/j.cose.2023.103319},
    url = {https://www.sciencedirect.com/science/article/pii/S0167404823002298},
    author = {Yanli Li and Dong Yuan and Abubakar Sadiq Sani and Wei Bao},
    keywords = {Federated learning (FL), Non-independent and identically distributed (Non-IID), Byzantine-robust aggregation, Untargeted model attack},
    abstract = {Federated Learning (FL) enables many clients to train a joint model without sharing the raw data. While many byzantine-robust FL methods have been proposed, FL remains vulnerable to security attacks such as poisoning attacks and evasion attacks due to its distributed adversarial environment. Additionally, real-world training data used in FL are usually Non-Independent and Identically Distributed (Non-IID), which further weakens the robustness of the existing FL methods (such as Krum, Median, Trimmed-Mean, etc.), thereby making it possible for a global model in FL to be broken in extreme Non-IID scenarios. In this work, we mitigate the aforementioned weaknesses of existing FL methods in Non-IID and adversarial scenarios by proposing a new FL framework called Mini-Federated Learning (Mini-FL). Mini-FL follows the general FL approach but considers the Non-IID sources of FL and aggregates the gradients by groups. Specifically, Mini-FL first performs unsupervised learning for the gradients received to define the grouping policy. Then, the server divides the gradients received into different groups according to the grouping policy defined and performs byzantine-robust aggregation. Finally, the server calculates the weighted mean of gradients from each group to update the global model. Owning the strong generality, Mini-FL can utilize the most existing byzantine-robust method. We demonstrate that Mini-FL effectively enhances FL robustness and achieves greater global accuracy than existing FL methods when against security attacks and in Non-IID settings.}
}

@misc{li2019abnormal,
      title={Abnormal Client Behavior Detection in Federated Learning}, 
      author={Suyi Li and Yong Cheng and Yang Liu and Wei Wang and Tianjian Chen},
      year={2019},
      eprint={1910.09933},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{yu2019understanding,
      title={Understanding Autoencoders with Information Theoretic Concepts}, 
      author={Shujian Yu and Jose C. Principe},
      year={2019},
      eprint={1804.00057},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{shwartzziv2017opening,
      title={Opening the Black Box of Deep Neural Networks via Information}, 
      author={Ravid Shwartz-Ziv and Naftali Tishby},
      year={2017},
      eprint={1703.00810},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{gadekallu2021federated,
      title={Federated Learning for Big Data: A Survey on Opportunities, Applications, and Future Directions}, 
      author={Thippa Reddy Gadekallu and Quoc-Viet Pham and Thien Huynh-The and Sweta Bhattacharya and Praveen Kumar Reddy Maddikunta and Madhusanka Liyanage},
      year={2021},
      eprint={2110.04160},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{Li_2020,
   title={Federated Learning: Challenges, Methods, and Future Directions},
   volume={37},
   ISSN={1558-0792},
   url={http://dx.doi.org/10.1109/MSP.2020.2975749},
   DOI={10.1109/msp.2020.2975749},
   number={3},
   journal={IEEE Signal Processing Magazine},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Li, Tian and Sahu, Anit Kumar and Talwalkar, Ameet and Smith, Virginia},
   year={2020},
   month=may, pages={50–60} }

@misc{li2019abnormal,
      title={Abnormal Client Behavior Detection in Federated Learning}, 
      author={Suyi Li and Yong Cheng and Yang Liu and Wei Wang and Tianjian Chen},
      year={2019},
      eprint={1910.09933},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{mcmahan2023communicationefficient,
      title={Communication-Efficient Learning of Deep Networks from Decentralized Data}, 
      author={H. Brendan McMahan and Eider Moore and Daniel Ramage and Seth Hampson and Blaise Agüera y Arcas},
      year={2023},
      eprint={1602.05629},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{article,
    author = {Ye, Yunfan and Li, Shen and Liu, Fang and Tang, Yonghao and Hu, Wanting},
    year = {2020},
    month = {01},
    pages = {209191-209198},
    title = {EdgeFed: Optimized Federated Learning Based on Edge Computing},
    volume = {8},
    journal = {IEEE Access},
    doi = {10.1109/ACCESS.2020.3038287}
}

@Article{s20216230,
AUTHOR = {Jiang, Ji Chu and Kantarci, Burak and Oktug, Sema and Soyata, Tolga},
TITLE = {Federated Learning in Smart City Sensing: Challenges and Opportunities},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {6230},
URL = {https://www.mdpi.com/1424-8220/20/21/6230},
PubMedID = {33142863},
ISSN = {1424-8220},
ABSTRACT = {Smart Cities sensing is an emerging paradigm to facilitate the transition into smart city services. The advent of the Internet of Things (IoT) and the widespread use of mobile devices with computing and sensing capabilities has motivated applications that require data acquisition at a societal scale. These valuable data can be leveraged to train advanced Artificial Intelligence (AI) models that serve various smart services that benefit society in all aspects. Despite their effectiveness, legacy data acquisition models backed with centralized Machine Learning models entail security and privacy concerns, and lead to less participation in large-scale sensing and data provision for smart city services. To overcome these challenges, Federated Learning is a novel concept that can serve as a solution to the privacy and security issues encountered within the process of data collection. This survey article presents an overview of smart city sensing and its current challenges followed by the potential of Federated Learning in addressing those challenges. A comprehensive discussion of the state-of-the-art methods for Federated Learning is provided along with an in-depth discussion on the applicability of Federated Learning in smart city sensing; clear insights on open issues, challenges, and opportunities in this field are provided as guidance for the researchers studying this subject matter.},
DOI = {10.3390/s20216230}
}

@misc{li2020federated,
      title={Federated Optimization in Heterogeneous Networks}, 
      author={Tian Li and Anit Kumar Sahu and Manzil Zaheer and Maziar Sanjabi and Ameet Talwalkar and Virginia Smith},
      year={2020},
      eprint={1812.06127},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@Article{electronics12102287,
AUTHOR = {Moshawrab, Mohammad and Adda, Mehdi and Bouzouane, Abdenour and Ibrahim, Hussein and Raad, Ali},
TITLE = {Reviewing Federated Learning Aggregation Algorithms; Strategies, Contributions, Limitations and Future Perspectives},
JOURNAL = {Electronics},
VOLUME = {12},
YEAR = {2023},
NUMBER = {10},
ARTICLE-NUMBER = {2287},
URL = {https://www.mdpi.com/2079-9292/12/10/2287},
ISSN = {2079-9292},
ABSTRACT = {The success of machine learning (ML) techniques in the formerly difficult areas of data analysis and pattern extraction has led to their widespread incorporation into various aspects of human life. This success is due in part to the increasing computational power of computers and in part to the improved ability of ML algorithms to process large amounts of data in various forms. Despite these improvements, certain issues, such as privacy, continue to hinder the development of this field. In this context, a privacy-preserving, distributed, and collaborative machine learning technique called federated learning (FL) has emerged. The core idea of this technique is that, unlike traditional machine learning, user data is not collected on a central server. Nevertheless, models are sent to clients to be trained locally, and then only the models themselves, without associated data, are sent back to the server to combine the different locally trained models into a single global model. In this respect, the aggregation algorithms play a crucial role in the federated learning process, as they are responsible for integrating the knowledge of the participating clients, by integrating the locally trained models to train a global one. To this end, this paper explores and investigates several federated learning aggregation strategies and algorithms. At the beginning, a brief summary of federated learning is given so that the context of an aggregation algorithm within a FL system can be understood. This is followed by an explanation of aggregation strategies and a discussion of current aggregation algorithms implementations, highlighting the unique value that each brings to the knowledge. Finally, limitations and possible future directions are described to help future researchers determine the best place to begin their own investigations.},
DOI = {10.3390/electronics12102287}
}

@Article{fi14050138,
AUTHOR = {Chen, Zheyi and Liao, Weixian and Tian, Pu and Wang , Qianlong and Yu, Wei},
TITLE = {A Fairness-Aware Peer-to-Peer Decentralized Learning Framework with Heterogeneous Devices},
JOURNAL = {Future Internet},
VOLUME = {14},
YEAR = {2022},
NUMBER = {5},
ARTICLE-NUMBER = {138},
URL = {https://www.mdpi.com/1999-5903/14/5/138},
ISSN = {1999-5903},
ABSTRACT = {Distributed machine learning paradigms have benefited from the concurrent advancement of deep learning and the Internet of Things (IoT), among which federated learning is one of the most promising frameworks, where a central server collaborates with local learners to train a global model. The inherent heterogeneity of IoT devices, i.e., non-independent and identically distributed (non-i.i.d.) data, and the inconsistent communication network environment results in the bottleneck of a degraded learning performance and slow convergence. Moreover, most weight averaging-based model aggregation schemes raise learning fairness concerns. In this paper, we propose a peer-to-peer decentralized learning framework to tackle the above issues. Particularly, each local client iteratively finds a learning pair to exchange the local learning model. By doing this, multiple learning objectives are optimized to advocate for learning fairness while avoiding small-group domination. The proposed fairness-aware approach allows local clients to adaptively aggregate the received model based on the local learning performance. The experimental results demonstrate that the proposed approach is capable of significantly improving the efficacy of federated learning and outperforms the state-of-the-art schemes under real-world scenarios, including balanced-i.i.d., unbalanced-i.i.d., balanced-non.i.i.d., and unbalanced-non.i.i.d. environments.},
DOI = {10.3390/fi14050138}
}

@misc{reguieg2023comparative,
      title={A Comparative Evaluation of FedAvg and Per-FedAvg Algorithms for Dirichlet Distributed Heterogeneous Data}, 
      author={Hamza Reguieg and Mohammed El Hanjri and Mohamed El Kamili and Abdellatif Kobbane},
      year={2023},
      eprint={2309.01275},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@INPROCEEDINGS{10184749,
  author={Chen, Min and Xu, Yang and Xu, Hongli and Huang, Liusheng},
  booktitle={2023 IEEE 39th International Conference on Data Engineering (ICDE)}, 
  title={Enhancing Decentralized Federated Learning for Non-IID Data on Heterogeneous Devices}, 
  year={2023},
  volume={},
  number={},
  pages={2289-2302},
  keywords={Training;Performance evaluation;Analytical models;Costs;Federated learning;Computational modeling;Heuristic algorithms;Edge Computing;Decentralized Federated Learning;Directed Communication;Neighbor Selection},
  doi={10.1109/ICDE55515.2023.00177}
}

@article{Li_2022,
   title={Decentralized Federated Learning via Mutual Knowledge Transfer},
   volume={9},
   ISSN={2372-2541},
   url={http://dx.doi.org/10.1109/JIOT.2021.3078543},
   DOI={10.1109/jiot.2021.3078543},
   number={2},
   journal={IEEE Internet of Things Journal},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Li, Chengxi and Li, Gang and Varshney, Pramod K.},
   year={2022},
   month=jan, pages={1136–1147} 
}

@misc{zhang2017deep,
      title={Deep Mutual Learning}, 
      author={Ying Zhang and Tao Xiang and Timothy M. Hospedales and Huchuan Lu},
      year={2017},
      eprint={1706.00384},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{roy2019braintorrent,
      title={BrainTorrent: A Peer-to-Peer Environment for Decentralized Federated Learning}, 
      author={Abhijit Guha Roy and Shayan Siddiqui and Sebastian Pölsterl and Nassir Navab and Christian Wachinger},
      year={2019},
      eprint={1905.06731},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@INPROCEEDINGS{9054055,
  author={Savazzi, Stefano and Nicoli, Monica and Rampa, Vittorio and Kianoush, Sanaz},
  booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Federated Learning with Mutually Cooperating Devices: A Consensus Approach Towards Server-Less Model Optimization}, 
  year={2020},
  volume={},
  number={},
  pages={3937-3941},
  keywords={Training;Wireless networks;Telecommunication traffic;Collaborative work;Data models;Servers;Statistics;Federated learning;consensus;cooperative networks;distributed intelligence;machine learning},
  doi={10.1109/ICASSP40776.2020.9054055}
}

@InProceedings{10.1007/978-3-540-30183-7_4,
author="Roussopoulos, Mema
and Baker, Mary
and Rosenthal, David S. H.
and Giuli, Thomas J.
and Maniatis, Petros
and Mogul, Jeff",
editor="Voelker, Geoffrey M.
and Shenker, Scott",
title="2 P2P or Not 2 P2P?",
booktitle="Peer-to-Peer Systems III",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="33--43",
abstract="In the hope of stimulating discussion, we present a heuristic decision tree that designers can use to judge how suitable a P2P solution might be for a particular problem. It is based on characteristics of a wide range of P2P systems from the literature, both proposed and deployed. These include budget, resource relevance, trust, rate of system change, and criticality.",
isbn="978-3-540-30183-7"
}

@misc{sagar2023poisoning,
      title={Poisoning Attacks and Defenses in Federated Learning: A Survey}, 
      author={Subhash Sagar and Chang-Sun Li and Seng W. Loke and Jinho Choi},
      year={2023},
      eprint={2301.05795},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}

@ARTICLE{10024252,
  author={Xia, Geming and Chen, Jian and Yu, Chaodong and Ma, Jun},
  journal={IEEE Access}, 
  title={Poisoning Attacks in Federated Learning: A Survey}, 
  year={2023},
  volume={11},
  number={},
  pages={10708-10722},
  keywords={Federated learning;Data models;Servers;Privacy;Distributed processing;Machine learning;Security;Federated learning;distributed machine learning;poisoning attacks;defense of poisoning attacks},
  doi={10.1109/ACCESS.2023.3238823}
}

@misc{cao2022fltrust,
      title={FLTrust: Byzantine-robust Federated Learning via Trust Bootstrapping}, 
      author={Xiaoyu Cao and Minghong Fang and Jia Liu and Neil Zhenqiang Gong},
      year={2022},
      eprint={2012.13995},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}

@misc{bhagoji2019analyzing,
      title={Analyzing Federated Learning through an Adversarial Lens}, 
      author={Arjun Nitin Bhagoji and Supriyo Chakraborty and Prateek Mittal and Seraphin Calo},
      year={2019},
      eprint={1811.12470},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@ARTICLE{9308910,
  author={Jere, Malhar S. and Farnan, Tyler and Koushanfar, Farinaz},
  journal={IEEE Security \& Privacy}, 
  title={A Taxonomy of Attacks on Federated Learning}, 
  year={2021},
  volume={19},
  number={2},
  pages={20-28},
  keywords={Data models;Collaborative work;Computational modeling;Servers;Security;Data privacy;Training data},
  doi={10.1109/MSEC.2020.3039941}
}

@misc{fung2020mitigating,
      title={Mitigating Sybils in Federated Learning Poisoning}, 
      author={Clement Fung and Chris J. M. Yoon and Ivan Beschastnikh},
      year={2020},
      eprint={1808.04866},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{Rodr_guez_Barroso_2023,
   title={Survey on federated learning threats: Concepts, taxonomy on attacks and defences, experimental study and challenges},
   volume={90},
   ISSN={1566-2535},
   url={http://dx.doi.org/10.1016/j.inffus.2022.09.011},
   DOI={10.1016/j.inffus.2022.09.011},
   journal={Information Fusion},
   publisher={Elsevier BV},
   author={Rodríguez-Barroso, Nuria and Jiménez-López, Daniel and Luzón, M. Victoria and Herrera, Francisco and Martínez-Cámara, Eugenio},
   year={2023},
   month=feb, pages={148–173} 
}

@misc{wang2022defense,
      title={Defense Strategies Toward Model Poisoning Attacks in Federated Learning: A Survey}, 
      author={Zhilin Wang and Qiao Kang and Xinyi Zhang and Qin Hu},
      year={2022},
      eprint={2202.06414},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}

@misc{nguyen2023backdoor,
      title={Backdoor Attacks and Defenses in Federated Learning: Survey, Challenges and Future Research Directions}, 
      author={Thuy Dung Nguyen and Tuan Nguyen and Phi Le Nguyen and Hieu H. Pham and Khoa Doan and Kok-Seng Wong},
      year={2023},
      eprint={2303.02213},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{feng2023sentinel,
      title={Sentinel: An Aggregation Function to Secure Decentralized Federated Learning}, 
      author={Chao Feng and Alberto Huertas Celdran and Janosch Baltensperger and Enrique Tomas Martinez Beltran and Gerome Bovet and Burkhard Stiller},
      year={2023},
      eprint={2310.08097},
      archivePrefix={arXiv},
      primaryClass={cs.DC}
}

@INPROCEEDINGS{8887357,
  author={Zhang, Jiale and Chen, Junjun and Wu, Di and Chen, Bing and Yu, Shui},
  booktitle={2019 18th IEEE International Conference On Trust, Security And Privacy In Computing And Communications/13th IEEE International Conference On Big Data Science And Engineering (TrustCom/BigDataSE)}, 
  title={Poisoning Attack in Federated Learning using Generative Adversarial Nets}, 
  year={2019},
  volume={},
  number={},
  pages={374-380},
  keywords={Data models;Training;Servers;Gallium nitride;Training data;Task analysis;Computational modeling;Federated learning, poisoning attack, generative adversarial nets, security, privacy},
  doi={10.1109/TrustCom/BigDataSE.2019.00057}
}

@misc{shejwalkar2021drawing,
      title={Back to the Drawing Board: A Critical Evaluation of Poisoning Attacks on Production Federated Learning}, 
      author={Virat Shejwalkar and Amir Houmansadr and Peter Kairouz and Daniel Ramage},
      year={2021},
      eprint={2108.10241},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@Article{fi13030073,
AUTHOR = {Zhou, Xingchen and Xu, Ming and Wu, Yiming and Zheng, Ning},
TITLE = {Deep Model Poisoning Attack on Federated Learning},
JOURNAL = {Future Internet},
VOLUME = {13},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {73},
URL = {https://www.mdpi.com/1999-5903/13/3/73},
ISSN = {1999-5903},
ABSTRACT = {Federated learning is a novel distributed learning framework, which enables thousands of participants to collaboratively construct a deep learning model. In order to protect confidentiality of the training data, the shared information between server and participants are only limited to model parameters. However, this setting is vulnerable to model poisoning attack, since the participants have permission to modify the model parameters. In this paper, we perform systematic investigation for such threats in federated learning and propose a novel optimization-based model poisoning attack. Different from existing methods, we primarily focus on the effectiveness, persistence and stealth of attacks. Numerical experiments demonstrate that the proposed method can not only achieve high attack success rate, but it is also stealthy enough to bypass two existing defense methods.},
DOI = {10.3390/fi13030073}
}

@ARTICLE{9806416,
  author={Gong, Xueluan and Chen, Yanjiao and Wang, Qian and Kong, Weihan},
  journal={IEEE Wireless Communications}, 
  title={Backdoor Attacks and Defenses in Federated Learning: State-of-the-Art, Taxonomy, and Future Directions}, 
  year={2023},
  volume={30},
  number={2},
  pages={114-121},
  keywords={Federated learning;Collaborative work;Servers;Data models;Anomaly detection;Adaptation models;Training data},
  doi={10.1109/MWC.017.2100714}}

@book{zhang2023dive,
  title={Dive into deep learning},
  author={Zhang, Aston and Lipton, Zachary C and Li, Mu and Smola, Alexander J},
  year={2023},
  publisher={Cambridge University Press}
}

@misc{mallah2022untargeted,
      title={Untargeted Poisoning Attack Detection in Federated Learning via Behavior Attestation}, 
      author={Ranwa Al Mallah and David Lopez and Godwin Badu Marfo and Bilal Farooq},
      year={2022},
      eprint={2101.10904},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}

@article{shannon1948mathematical,
  title={A mathematical theory of communication},
  author={Shannon, Claude Elwood},
  journal={The Bell system technical journal},
  volume={27},
  number={3},
  pages={379--423},
  year={1948},
  publisher={Nokia Bell Labs}
}

@ARTICLE{9082644,
  author={Goldfeld, Ziv and Polyanskiy, Yury},
  journal={IEEE Journal on Selected Areas in Information Theory}, 
  title={The Information Bottleneck Problem and its Applications in Machine Learning}, 
  year={2020},
  volume={1},
  number={1},
  pages={19-38},
  keywords={Mutual information;Deep learning;Training;IP networks;Noise measurement;Deep learning;information bottleneck;machine learning;mutual information;neural networks},
  doi={10.1109/JSAIT.2020.2991561}}

@misc{kawaguchi2023does,
      title={How Does Information Bottleneck Help Deep Learning?}, 
      author={Kenji Kawaguchi and Zhun Deng and Xu Ji and Jiaoyang Huang},
      year={2023},
      eprint={2305.18887},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{
michael2018on,
title={On the Information Bottleneck Theory of Deep Learning},
author={Andrew Michael Saxe and Yamini Bansal and Joel Dapello and Madhu Advani and Artemy Kolchinsky and Brendan Daniel Tracey and David Daniel Cox},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=ry_WPG-A-},
}

@inproceedings{krum,
 author = {Blanchard, Peva and El Mhamdi, El Mahdi and Guerraoui, Rachid and Stainer, Julien},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Machine Learning with Adversaries: Byzantine Tolerant Gradient Descent},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/f4b9ec30ad9f68f89b29639786cb62ef-Paper.pdf},
 volume = {30},
 year = {2017}
}

@misc{trimmed,
      title={Byzantine-Robust Distributed Learning: Towards Optimal Statistical Rates}, 
      author={Dong Yin and Yudong Chen and Kannan Ramchandran and Peter Bartlett},
      year={2021},
      eprint={1803.01498},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@INPROCEEDINGS{median,
  author={Yin, Jie and Cui, Xiang and Li, Ke},
  booktitle={2017 IEEE Second International Conference on Data Science in Cyberspace (DSC)}, 
  title={A Reputation-Based Resilient and Recoverable P2P Botnet}, 
  year={2017},
  volume={},
  number={},
  pages={275-282},
  keywords={Peer-to-peer computing;IP networks;Robustness;Protocols;Servers;Pollution;botnet;peer-to-peer;resilient;recoverable;peer-list;reputation},
  doi={10.1109/DSC.2017.20}}

@misc{bagdasaryan2019backdoor,
      title={How To Backdoor Federated Learning}, 
      author={Eugene Bagdasaryan and Andreas Veit and Yiqing Hua and Deborah Estrin and Vitaly Shmatikov},
      year={2019},
      eprint={1807.00459},
      archivePrefix={arXiv}
}

@misc{bulyan,
      title={The Hidden Vulnerability of Distributed Learning in Byzantium}, 
      author={El Mahdi El Mhamdi and Rachid Guerraoui and Sébastien Rouault},
      year={2018},
      eprint={1802.07927},
      archivePrefix={arXiv}
}

@inproceedings {259745,
author = {Clement Fung and Chris J. M. Yoon and Ivan Beschastnikh},
title = {The Limitations of Federated Learning in Sybil Settings},
booktitle = {23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020)},
year = {2020},
isbn = {978-1-939133-18-2},
address = {San Sebastian},
pages = {301--316},
url = {https://www.usenix.org/conference/raid2020/presentation/fung},
publisher = {USENIX Association},
month = oct
}

@inproceedings{Rieger_2022, series={NDSS 2022},
   title={DeepSight: Mitigating Backdoor Attacks in Federated Learning Through Deep Model Inspection},
   url={http://dx.doi.org/10.14722/ndss.2022.23156},
   DOI={10.14722/ndss.2022.23156},
   booktitle={Proceedings 2022 Network and Distributed System Security Symposium},
   publisher={Internet Society},
   author={Rieger, Phillip and Nguyen, Thien Duc and Miettinen, Markus and Sadeghi, Ahmad-Reza},
   year={2022},
   collection={NDSS 2022} }

@misc{li2022lomar,
      title={LoMar: A Local Defense Against Poisoning Attack on Federated Learning}, 
      author={Xingyu Li and Zhe Qu and Shangqing Zhao and Bo Tang and Zhuo Lu and Yao Liu},
      year={2022},
      eprint={2201.02873},
      archivePrefix={arXiv}
}

@misc{spectral,
      title={Learning to Detect Malicious Clients for Robust Federated Learning}, 
      author={Suyi Li and Yong Cheng and Wei Wang and Yang Liu and Tianjian Chen},
      year={2020},
      eprint={2002.00211},
      archivePrefix={arXiv}
}

@misc{lianga2023survey,
      title={A Survey on Federated Learning Poisoning Attacks and Defenses}, 
      author={Junchuan Lianga and Rong Wang and Chaosheng Feng and Chin-Chen Chang},
      year={2023},
      eprint={2306.03397},
      archivePrefix={arXiv}
}

@article{Zhang2024Anomaly,
  author    = {Zhang, C. and Yang, S. and Mao, L. and others},
  title     = {Anomaly Detection and Defense Techniques in Federated Learning: A Comprehensive Review},
  journal   = {Artificial Intelligence Review},
  volume    = {57},
  pages     = {150},
  year      = {2024},
  doi       = {10.1007/s10462-024-10796-1}
}

@misc{du2019robust,
      title={Robust Anomaly Detection and Backdoor Attack Detection Via Differential Privacy}, 
      author={Min Du and Ruoxi Jia and Dawn Song},
      year={2019},
      eprint={1911.07116},
      archivePrefix={arXiv}
}

@misc{wei2019federated,
      title={Federated Learning with Differential Privacy: Algorithms and Performance Analysis}, 
      author={Kang Wei and Jun Li and Ming Ding and Chuan Ma and Howard H. Yang and Farokhi Farhad and Shi Jin and Tony Q. S. Quek and H. Vincent Poor},
      year={2019},
      eprint={1911.00222},
      archivePrefix={arXiv}
}

@inproceedings {flame,
author = {Thien Duc Nguyen and Phillip Rieger and Huili Chen and Hossein Yalame and Helen M{\"o}llering and Hossein Fereidooni and Samuel Marchal and Markus Miettinen and Azalia Mirhoseini and Shaza Zeitouni and Farinaz Koushanfar and Ahmad-Reza Sadeghi and Thomas Schneider},
title = {{FLAME}: Taming Backdoors in Federated Learning},
booktitle = {31st USENIX Security Symposium (USENIX Security 22)},
year = {2022},
isbn = {978-1-939133-31-1},
address = {Boston, MA},
pages = {1415--1432},
url = {https://www.usenix.org/conference/usenixsecurity22/presentation/nguyen},
publisher = {USENIX Association},
month = aug}

@inproceedings{
park2021sageflow,
title={Sageflow: Robust Federated Learning against Both Stragglers and Adversaries},
author={Jungwuk Park and Dong-Jun Han and Minseok Choi and Jaekyun Moon},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
url={https://openreview.net/forum?id=rA9HFxFT7th}
}

@INPROCEEDINGS{9700624,
  author={Gholami, Anousheh and Torkzaban, Nariman and Baras, John S.},
  booktitle={2022 IEEE 19th Annual Consumer Communications \& Networking Conference (CCNC)}, 
  title={Trusted Decentralized Federated Learning}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  keywords={Training;Privacy;Scalability;Neural networks;Packet loss;Collaborative work;Inference algorithms;Federated learning;consensus algorithm;trust aggregation;trusted federated learning},
  doi={10.1109/CCNC49033.2022.9700624}}

@article{FedInv, title={FedInv: Byzantine-Robust Federated Learning by Inversing Local Model Updates}, volume={36}, url={https://ojs.aaai.org/index.php/AAAI/article/view/20903}, DOI={10.1609/aaai.v36i8.20903}, abstractNote={Federated learning (FL) is a privacy-preserving distributed machine learning paradigm that enables multiple clients to collaboratively train statistical models without disclosing raw training data. However, the inaccessible local training data and uninspectable local training process make FL susceptible to various Byzantine attacks (e.g., data poisoning and model poisoning attacks), aiming to manipulate the FL model training process and degrade the model performance. Most of the existing Byzantine-robust FL schemes cannot effectively defend against stealthy poisoning attacks that craft poisoned models statistically similar to benign models. Things worsen when many clients are compromised or data among clients are highly non-independent and identically distributed (non-IID). In this work, to address these issues, we propose FedInv, a novel Byzantine-robust FL framework by inversing local model updates. Specifically, in each round of local model aggregation in FedInv, the parameter server first inverses the local model updates submitted by each client to generate a corresponding dummy dataset. Then, the server identifies those dummy datasets with exceptional Wasserstein distances from others and excludes the related local model updates from model aggregation. We conduct an exhaustive experimental evaluation of FedInv. The results demonstrate that FedInv significantly outperforms the existing robust FL schemes in defending against stealthy poisoning attacks under highly non-IID data partitions.}, number={8}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Zhao, Bo and Sun, Peng and Wang, Tao and Jiang, Keyu}, year={2022}, month={Jun.}, pages={9171-9179} }

@inproceedings{VFedAD, author = {Lai, Jinrong and Wang, Tong and Chen, Chuan and Li, Yihao and Zheng, Zibin}, title = {VFedAD: A Defense Method Based on the Information Mechanism Behind the Vertical Federated Data Poisoning Attack}, year = {2023}, isbn = {9798400701245}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3583780.3615106}, doi = {10.1145/3583780.3615106}, abstract = {In recent years, federated learning has achieved remarkable results in the medical and financial fields, but various attacks have always plagued federated learning. Data poisoning attack and defense research in horizontal federated learning are sufficient, yet vertical federated data poisoning attack and defense remains an open area due to two challenges: (1) Complex data distributions lead to immense attack possibilities, and (2) defense methods are insufficient for complex data distributions. We have discovered that from the perspective of information theory, the above challenges can be addressed elegantly and succinctly with a solution. We first reveal the information-theoretic mechanisms underlying vertical federated data poisoning attacks and then propose an unsupervised vertical federated data poisoning defense method (VFedAD) based on information theory. VFedAD learns semantic-rich client data representations through contrastive learning task and cross-client prediction task to identify anomalies. Experiments show VFedAD effectively detects vertical federated anomalies, protecting subsequent algorithms from vertical federated data poisoning attacks.}, booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management}, pages = {1148–1157}, numpages = {10}, keywords = {vertical federated learning, information theory, data poisoning attack and defense}, location = {, Birmingham, United Kingdom, }, series = {CIKM '23} }

@misc{Akash_Panchal_2020,
  author    = {Akash Panchal},
  title     = {Machine Learning: Improving Classification accuracy on MNIST using Data Augmentation - An easy way to grow the training data set},
  year      = {2020},
  url       = {https://towardsdatascience.com/improving-accuracy-on-mnist-using-data-augmentation-b5c38eb5a903},
  note      = {Accessed: Jun 25, 2024}
}

@misc{Evidently_2024,
  author    = {Evidently AI Team},
  title     = {How to interpret a confusion matrix for a machine learning model},
  year      = {2024},
  url       = {https://www.evidentlyai.com/classification-metrics/confusion-matrix},
  note      = {Accessed: Jun 25, 2024}
}

@misc{noise,
  author    = {Coursesteach},
  title     = {Computer Vision (Part 14)-Common Types of Noise},
  year      = {2023},
  month     = {Dec},
  url       = {https://medium.com/@Coursesteach/computer-vision-part-14-common-types-of-noise-7e6507cc763c},
  note      = {Accessed: Jun 22, 2024}
}

@misc{mnist,
  author = {LeCun, Yann and Cortes, Corinna},
  title = {{MNIST handwritten digit database}},
  year = {2010},
  howpublished = {\url{http://yann.lecun.com/exdb/mnist/}},
  note = {Accessed: Jun 28, 2024}
}

@misc{xiao2017fashionmnistnovelimagedataset,
      title={Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms}, 
      author={Han Xiao and Kashif Rasul and Roland Vollgraf},
      year={2017},
      eprint={1708.07747},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1708.07747}, 
}

@article{cifar10,
author = {Krizhevsky, Alex},
year = {2012},
month = {05},
pages = {},
title = {Learning Multiple Layers of Features from Tiny Images},
journal = {University of Toronto}
}

@misc{he2015deepresiduallearningimage,
      title={Deep Residual Learning for Image Recognition}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1512.03385},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1512.03385}, 
}